---
title: "Linear Regression - Example Project"
author: "Marina Wyss"
date: "8/17/2019"
output: html_document
---

```{r setup, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(readr)
library(dplyr)
library(GGally)
library(kableExtra)
library(caTools)
library(stargazer)
```
# Linear Regression - Example Project

Imagine that you've just got some contract work with an e-commerce company that sells clothing online, but they also have in-store style and clothing advice sessions. Customers come in to the store, have sessions/meetings with a personal stylist, then they can go home and order either on a mobile app or website for the clothes they want.

The company is trying to decide whether to focus their efforts on their mobile app experience or their website. 

The data is obviously fake, and this example is heavily inspired by Pierian Data's Python course on Udemy.

## Get the Data & Take a Look
```{r data}
# read in the Ecommerce Customers csv file as a DataFrame called customers.
customers <- read_csv("EcommerceCustomers")
```
We'll work with the Ecommerce Customers csv file from the company. It has customer info, such as email, address, and their color avatar. Then it also has numerical value columns:

* Avg. Session Length: Average session of in-store style advice sessions.
* Time on App: Average time spent on App in minutes
* Time on Website: Average time spent on Website in minutes
* Length of Membership: How many years the customer has been a member. 

```{r exploring the data}
head(customers)
summary(customers)
str(customers)
```

```{r any null}
# checking if we have any NA values
any(is.na(customers))
```
## Data Manipulation/Clean-up

Let's drop the unused columns. This isn't necessary, let's just do it for practice.
```{r dropping cols}
customers <- customers %>% select(-Email, -Address, -Avatar)
```

Then, let's change the column names to get rid of the spaces. They are annoying in R.
```{r renaming}
customers <- customers %>% 
  rename(
    avgSessionLength = 'Avg. Session Length',
    timeOnApp = 'Time on App',
    timeOnWebsite = 'Time on Website',
    lengthOfMembership = 'Length of Membership',
    yearlyAmountSpent =  'Yearly Amount Spent'
    )
```
Since we don't have any categorical data, let's create a new column for gender. Here we create a new column that has gender as a factor of Male and Female, with 40% men and 60% women.

```{r new gender col}
customers$Gender <- as.factor(sample(c("Female", "Male"), 
                                     size = length(customers$yearlyAmountSpent), 
                                     replace = TRUE, 
                                     prob = c(0.60, 0.40)))
```
Just to make it interesting, let's change their spending behaviors a bit.

```{r mutate}
customers$yearlyAmountSpent <- ifelse(customers$`Gender` == 'Male', 
       customers$yearlyAmountSpent * 0.75, 
       customers$yearlyAmountSpent)

customers$lengthOfMembership <- ifelse(customers$`Gender` == 'Male', 
       customers$lengthOfMembership * 1.10, 
       customers$lengthOfMembership)

customers$timeOnApp <- ifelse(customers$`Gender` == 'Male', 
       customers$timeOnApp * 0.85, 
       customers$timeOnApp)

# checking that it worked
kable(customers %>% group_by(Gender) %>% summarise_all("mean")) %>% kable_styling()
```


## Exploratory Data Analysis

```{r plotting, message = FALSE}
# is y close to normally distributed?
ggplot(customers, aes(x = yearlyAmountSpent)) + geom_histogram()

# outliers?
ggplot(customers, aes(x = Gender, y = yearlyAmountSpent)) + geom_boxplot(aes(fill = Gender))

ggpairs(customers)
```

<br>Length of Membership and Time on App seem to be the most relevant factors. Let's investigate a bit more.

```{r plotting lm, message = FALSE}
ggplot(customers, aes(x = lengthOfMembership, y = yearlyAmountSpent, color = Gender)) + 
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE)

ggplot(customers, aes(x = timeOnApp, y = yearlyAmountSpent, color = Gender)) + 
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE)
```

## Training and Test Data

<br>Write something here about why we do this

```{r train test}
# set a random see so your "random" results are the same as mine
set.seed(101) 

# split up the sample, basically randomly assigns a booleans to a new column "sample"
sample <- sample.split(customers$yearlyAmountSpent, SplitRatio = 0.70) 

# training Data
train = subset(customers, sample == TRUE)

# testing Data
test = subset(customers, sample == FALSE)
```

Now, it's time to model our data!
```{r lm}
# we create the model using training data
model <- lm(yearlyAmountSpent ~ avgSessionLength + timeOnApp + timeOnWebsite + lengthOfMembership + Gender, data = train)
```
## Prediction
```{r preds}
predictions <- predict(model, test)

ggplot(test, aes(x = yearlyAmountSpent, y = predictions)) + 
  geom_point() +
  labs(y = "predicted y", x = "y test")
```
<br>Our model is doing very well! It would be a completely straight line with the points on top of each other if it was perfect. 


## Model Evaluation
<br>Let's evaluate our model performance by calculating the residual sum of squares and the explained variance score (R-squared).

```{r math stuff}
results <- cbind(predictions, test$yearlyAmountSpent) 
colnames(results) <- c('pred','real')
results <- as.data.frame(results)

mse <- mean((results$real-results$pred)^2)
            
print(paste0("MSE: ", mse))
print(paste0("RMSE: ", mse^0.5))
```
<br>Then, let's plot the residuals.

```{r residuals}
res <- as.data.frame(residuals(model))

ggplot(res, aes(x = residuals(model))) +  geom_histogram(bins = 50)
```
<br>Our residuals look normally distributed. Hooray.

## Interpretation
Since we know our model is looking good, let's take a stab at evaluating our model:

```{r model, results='asis'}
stargazer(model, 
          type = "html", 
          intercept.bottom = FALSE)
```
<br>
<br>
Interpreting the coefficients:

- Holding all other features fixed, a 1 unit increase in <b>Avg. Session Length</b> is associated with an <b>increase of 22.41 total dollars spent</b>.
- Holding all other features fixed, a 1 unit increase in <b>Time on App</b> is associated with an <b>increase of 37.60 total dollars spent</b>.
- Holding all other features fixed, a 1 unit increase in <b>Time on Website</b> is associated with an <b>increase of 0.89 total dollars spent</b>.
- Holding all other features fixed, a 1 unit increase in <b>Length of Membership</b> is associated with an <b>increase of 52.19 total dollars spent</b>.
- Holding all other features fixed, being <b>Male</b> is associated with an <b>decrease of 75.46 total dollars spent.


This is tricky, there are two ways to think about this: Develop the Website to catch up to the performance of the mobile app, or develop the app more since that is what is working better. This sort of answer really depends on the other factors going on at the company, you would probably want to explore the relationship between Length of Membership and the App or the Website before coming to a conclusion!

Something about gender